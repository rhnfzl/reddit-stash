name: Reddit Stash Scraper

on:
  schedule:
    # TIMEZONE INFORMATION: 
    # - GitHub Actions uses UTC time for all cron schedules
    # - Netherlands is UTC+1 (CET) in winter and UTC+2 (CEST) in summer
    # - To convert from your local time to UTC: subtract your UTC offset (e.g., for Netherlands CEST: 14:00 CEST - 2 hours = 12:00 UTC)
    # - To convert from UTC to your local time: add your UTC offset (e.g., for Netherlands CEST: 12:00 UTC + 2 hours = 14:00 CEST)
    #
    # ADJUSTING FOR YOUR TIMEZONE:
    # 1. Determine your timezone's UTC offset (examples: US Eastern = UTC-4/5, Japan = UTC+9, UK = UTC+0/1)
    # 2. For desired local time X, set the UTC time to: X - (your UTC offset)
    # 3. Update both cron expressions below with your calculated UTC times
    
    # Higher frequency during Netherlands peak hours (8:00-23:00 CEST = 6:00-21:00 UTC)
    - cron: "0 6-21/2 * * *"  # Every 2 hours during peak hours (converts to 8:00-23:00 Netherlands time in summer)
    
    # Lower frequency during Netherlands off-peak hours
    - cron: "0 23,3 * * *"    # Twice during off-peak (converts to 1:00 and 5:00 Netherlands time in summer)
  
  workflow_dispatch:           # Manual trigger option

# Add concurrency to cancel redundant runs
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  run-script:
    runs-on: ubuntu-latest
    timeout-minutes: 15  # Kill job if it runs longer than 15 minutes
    container:
      image: python:3.10-slim
      
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
      timeout-minutes: 1  # Checkout should be quick

    # Get date for monthly cache refresh - add to requirements hash
    - name: Create monthly requirements file hash
      id: req_hash
      timeout-minutes: 1
      run: |
        apt-get update && apt-get install -y --no-install-recommends git
        month_year=$(date +'%Y-%m')
        echo "hash=$month_year-$(sha256sum requirements.txt | cut -d' ' -f1)" >> $GITHUB_OUTPUT

    # Try to restore compressed Reddit data cache
    - name: Restore Reddit data from cache
      id: cache-data
      timeout-minutes: 2
      uses: actions/cache@v3
      with:
        path: ./reddit-data.tar.gz
        key: reddit-data-${{ github.run_id }}
        restore-keys: |
          reddit-data-

    # Extract cache if found
    - name: Extract Reddit data if cache hit
      if: steps.cache-data.outputs.cache-hit == 'true'
      run: |
        apt-get update && apt-get install -y --no-install-recommends tar gzip
        mkdir -p ./data
        tar -xzf ./reddit-data.tar.gz -C ./
        echo "Data restored from cache"

    # Set up pip cache
    - name: Cache pip packages
      timeout-minutes: 2
      uses: actions/cache@v3
      with:
        path: /root/.cache/pip
        key: ${{ runner.os }}-pip-${{ steps.req_hash.outputs.hash }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      timeout-minutes: 3
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    # Only download from Dropbox if cache miss or daily sync needed
    - name: Check if daily sync with Dropbox is needed
      id: check-sync
      run: |
        # If it's midnight UTC or manual trigger, force Dropbox sync
        if [[ "$(date +'%H')" == "00" ]] || [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
          echo "need_sync=true" >> $GITHUB_OUTPUT
        elif [[ "${{ steps.cache-data.outputs.cache-hit }}" != "true" ]]; then
          echo "need_sync=true" >> $GITHUB_OUTPUT
        else
          echo "need_sync=false" >> $GITHUB_OUTPUT
        fi

    - name: Download existing Reddit data from Dropbox
      if: steps.check-sync.outputs.need_sync == 'true'
      timeout-minutes: 5
      env:
        DROPBOX_REFRESH_TOKEN: ${{ secrets.DROPBOX_REFRESH_TOKEN }}
        DROPBOX_APP_KEY: ${{ secrets.DROPBOX_APP_KEY }}
        DROPBOX_APP_SECRET: ${{ secrets.DROPBOX_APP_SECRET }}
      run: |
        python dropbox_utils.py --download  # download the files

    - name: Run Reddit Stash Script
      timeout-minutes: 5
      env:
        REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
        REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
        REDDIT_USERNAME: ${{ secrets.REDDIT_USERNAME }}
        REDDIT_PASSWORD: ${{ secrets.REDDIT_PASSWORD }}
      run: |
        python reddit_stash.py  # process the files

    # Compress data directory to speed up cache storage
    - name: Compress data for caching
      run: |
        apt-get update && apt-get install -y --no-install-recommends tar gzip
        tar -czf reddit-data.tar.gz ./data

    # Only upload to Dropbox if data was updated
    - name: Upload updated Reddit data to Dropbox
      timeout-minutes: 5
      env:
        DROPBOX_REFRESH_TOKEN: ${{ secrets.DROPBOX_REFRESH_TOKEN }}
        DROPBOX_APP_KEY: ${{ secrets.DROPBOX_APP_KEY }}
        DROPBOX_APP_SECRET: ${{ secrets.DROPBOX_APP_SECRET }}
      run: |
        python dropbox_utils.py --upload  # upload the files